# Text Summarization using IBM watsonx.ai
IBM watsonx AI offers generative AI capabilities powered by foundation models and traditional machine learning. In watsonx.ai, you have access to IBM selected open source models from Hugging Face, as well as other third-party models including Llama-2-chat and StarCoder LLM for code generation, and a family of IBM-trained foundation models of different sizes and architectures. These models start with Slate for non-generative AI tasks and the Granite series models that use a decoder architecture to support a variety of enterprise NLP generative AI tasks.

This repository demonstrates how to use [watson machine learning](https://ibm.github.io/watson-machine-learning-sdk/) Python SDK to call watsonx.ai models from Cloudera Machine Learning (CML) workspace. In this [Applied ML Prototype (AMP)](https://docs.cloudera.com/machine-learning/cloud/applied-ml-prototypes/topics/ml-amps-overview.html), text summarization based on custom instruction is used as an example but these foundation models are capable of much more such as question-answering, classification, extraction and so on.

## AMP Overview
